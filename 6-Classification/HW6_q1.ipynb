{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: Classification\n",
    "\n",
    "### _Sushmita V Gopalan_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For ML\n",
    "import sklearn\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import sklearn.neural_network\n",
    "import sklearn.decomposition\n",
    "\n",
    "import nltk #For tokenizing and normalizing\n",
    "import numpy as np #arrays\n",
    "import matplotlib.pyplot as plt #Plots\n",
    "import matplotlib.colors # For nice colours\n",
    "import seaborn #Makes plots look nice, also heatmaps\n",
    "import scipy as sp #for interp\n",
    "\n",
    "#These are from the standard library\n",
    "import collections\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Reddit data\n",
      "Converting to vectors\n",
      "Loading data for: comp.sys.mac.hardware\n",
      "Loading data for: comp.windows.x\n",
      "Loading data for: misc.forsale\n",
      "Loading data for: rec.autos\n",
      "Converting to vectors\n",
      "Loading senate data\n",
      "Converting to vectors\n",
      "Loading senator: Kennedy\n",
      "Loading senator: Kerry\n",
      "Loading senator: Klobuchar\n",
      "Loading senator: Kohl\n",
      "Loading senator: Kyl\n",
      "Converting to vectors\n",
      "Loading Spam\n",
      "Loading Ham\n",
      "Converting to vectors\n",
      "CPU times: user 2min 20s, sys: 3.52 s, total: 2min 23s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Creating 10 artificial datasets \n",
    "\n",
    "train1, test1 = lucem_illud.trainTestSplit(lucem_illud.random())\n",
    "\n",
    "noise = 0.1\n",
    "train2, test2 = lucem_illud.trainTestSplit(lucem_illud.andSplit(noise))\n",
    "train3, test3 = lucem_illud.trainTestSplit(lucem_illud.xorSplit(noise)) #Please try this one\n",
    "train4, test4 = lucem_illud.trainTestSplit(lucem_illud.targetSplit(noise))\n",
    "train5, test5 = lucem_illud.trainTestSplit(lucem_illud.multiBlobs(noise))\n",
    "\n",
    "noise = 0.5 \n",
    "\n",
    "train6, test6 = lucem_illud.trainTestSplit(lucem_illud.andSplit(noise))\n",
    "train7, test7 = lucem_illud.trainTestSplit(lucem_illud.xorSplit(noise)) #Please try this one\n",
    "train8, test8 = lucem_illud.trainTestSplit(lucem_illud.targetSplit(noise))\n",
    "train9, test9 = lucem_illud.trainTestSplit(lucem_illud.multiBlobs(noise))\n",
    "\n",
    "noise = 0.9\n",
    "\n",
    "train10, test10 = lucem_illud.trainTestSplit(lucem_illud.andSplit(noise))\n",
    "train11, test11 = lucem_illud.trainTestSplit(lucem_illud.xorSplit(noise)) #Please try this one\n",
    "train12, test12 = lucem_illud.trainTestSplit(lucem_illud.targetSplit(noise))\n",
    "train13, test13 = lucem_illud.trainTestSplit(lucem_illud.multiBlobs(noise))\n",
    "\n",
    "# loading other datasets\n",
    "train14, test14 = lucem_illud.trainTestSplit(lucem_illud.loadReddit())\n",
    "train15, test15 = lucem_illud.trainTestSplit(lucem_illud.loadNewsGroups())\n",
    "train16, test16 = lucem_illud.trainTestSplit(lucem_illud.loadSenateSmall())\n",
    "train17, test17 = lucem_illud.trainTestSplit(lucem_illud.loadSenateLarge())\n",
    "train18, test18 = lucem_illud.trainTestSplit(lucem_illud.loadSpam())\n",
    "\n",
    "trains = [train1, train2, train3, train4, train5, train6, train7, train8, train9, train10, train11, train12, train13, train14, train15, train16, train17, train18]\n",
    "tests = [test1, test2, test3, test4, test5, test6, test7, test8, test9, test10, test11, test12, test13, test14, test15, test16, test17, test18]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 153 ms, sys: 4.98 ms, total: 158 ms\n",
      "Wall time: 158 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def auc(clf,train,test):\n",
    "    clf.fit(np.stack(train['vect'], axis=0), train['category'])\n",
    "    return lucem_illud.evaluateClassifier(clf, test)['AUC'][0]\n",
    "\n",
    "# Naive Bayes\n",
    "clf = sklearn.naive_bayes.GaussianNB()\n",
    "naive_bayes = []\n",
    "for i in range(0,13):\n",
    "    x = auc(clf,trains[i],tests[i])\n",
    "    naive_bayes.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 240 ms, sys: 8.98 ms, total: 249 ms\n",
      "Wall time: 248 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SVM - Linear Kernel\n",
    "clf = sklearn.svm.SVC(kernel = 'linear', probability = False) #slow, set probability = False to speed up\n",
    "svm_linear = []\n",
    "for i in range(0,13):\n",
    "    x = auc(clf,trains[i],tests[i])\n",
    "    svm_linear.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 7.47 ms, total: 1.28 s\n",
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SVM - Cubic Kernel\n",
    "clf = sklearn.svm.SVC(kernel = 'poly', degree = 3, probability = False) #slower\n",
    "svm_cubic = []\n",
    "for i in range(0,13):\n",
    "    x = auc(clf,trains[i],tests[i])\n",
    "    svm_cubic.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 151 ms, sys: 4.19 ms, total: 156 ms\n",
      "Wall time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# knn\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(5, weights='distance')# k, 'distance' or 'uniform'\n",
    "knn = []\n",
    "for i in range(0,13):\n",
    "    x = auc(clf,trains[i],tests[i])\n",
    "    knn.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 173 ms, sys: 2.83 ms, total: 176 ms\n",
      "Wall time: 176 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# logistic regression\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "logit = []\n",
    "for i in range(0,13):\n",
    "    x = auc(clf,trains[i],tests[i])\n",
    "    logit.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 170 ms, sys: 2.86 ms, total: 173 ms\n",
      "Wall time: 173 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# decision tree\n",
    "clf = sklearn.tree.DecisionTreeClassifier()\n",
    "dt = []\n",
    "for i in range(0,13):\n",
    "    x = auc(clf,trains[i],tests[i])\n",
    "    dt.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 394 ms, sys: 3.74 ms, total: 397 ms\n",
      "Wall time: 403 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# random forest\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "rf = []\n",
    "for i in range(0,13):\n",
    "    x = auc(clf,trains[i],tests[i])\n",
    "    rf.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.69 s, sys: 771 ms, total: 7.46 s\n",
      "Wall time: 7.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# mlpc\n",
    "clf = sklearn.neural_network.MLPClassifier()\n",
    "mlpc = []\n",
    "for i in range(0,13):\n",
    "    x = auc(clf,trains[i],tests[i])\n",
    "    mlpc.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.67 s, sys: 23.5 ms, total: 2.69 s\n",
      "Wall time: 2.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# gradient boosting\n",
    "clf = sklearn.ensemble.GradientBoostingClassifier()\n",
    "gb = []\n",
    "for i in range(0,13):\n",
    "    x = auc(clf,trains[i],tests[i])\n",
    "    gb.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 12.5 ms, total: 1.35 s\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# adaboost\n",
    "clf = sklearn.ensemble.AdaBoostClassifier()\n",
    "adaboost = []\n",
    "for i in range(0,13):\n",
    "    x = auc(clf,trains[i],tests[i])\n",
    "    adaboost.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and split \n",
    "classifiers = [naive_bayes, svm_linear, svm_cubic, knn, logit, dt, rf, mlpc, gb]\n",
    "names = [\"Naive Bayes\", \"SVM(Linear)\", \"SVM(Cubic)\", \"K-NN\",\"Logistic Regression\",\"Decision Tree\",\n",
    "         \"Random Forest\",\"MLPC\",\"Gradient Boost\"]       \n",
    "data_and = []\n",
    "data_xor = []\n",
    "data_target = []\n",
    "data_blob = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    for i in [2,6,10]:\n",
    "        data_and.append(classifier[i-1])\n",
    "    for i in [3,7,11]:\n",
    "        data_xor.append(classifier[i-1])\n",
    "    for i in [4,8,12]:\n",
    "        data_target.append(classifier[i-1])\n",
    "    for i in [5,9,13]:\n",
    "        data_blob.append(classifier[i-1])\n",
    "\n",
    "\n",
    "and_low = []\n",
    "and_med = []\n",
    "and_high = []\n",
    "\n",
    "xor_low = []\n",
    "xor_med = []\n",
    "xor_high = []\n",
    "\n",
    "target_low = []\n",
    "target_med = []\n",
    "target_high = []\n",
    "\n",
    "blob_low = []\n",
    "blob_med = []\n",
    "blob_high = []\n",
    "\n",
    "for i in range(27):\n",
    "    if i in [0,3,6,9,12,15,18,21,24,27]:\n",
    "        and_low.append(data_and[i])\n",
    "        xor_low.append(data_xor[i])\n",
    "        target_low.append(data_target[i])\n",
    "        blob_low.append(data_blob[i])\n",
    "\n",
    "        \n",
    "    if i in [1,4,7,10,13,16,19,22,25,28]:\n",
    "        and_med.append(data_and[i])\n",
    "        xor_med.append(data_xor[i])\n",
    "        target_med.append(data_target[i])\n",
    "        blob_med.append(data_blob[i])\n",
    "\n",
    "\n",
    "    if i in [2,5,8,11,14,17,20,23,26,29]:\n",
    "        and_high.append(data_and[i])\n",
    "        xor_high.append(data_xor[i])\n",
    "        target_high.append(data_target[i])\n",
    "        blob_high.append(data_blob[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(names)\n",
    "len(and_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "and_df = pd.DataFrame({'0.Classifier':names, \n",
    "                       '1. Low Noise':and_low, \n",
    "                       '2. Medium Noise':and_med, \n",
    "                       '3. High Noise':and_high})\n",
    "xor_df = pd.DataFrame({'0.Classifier':names, \n",
    "                       '1. Low Noise':xor_low, \n",
    "                       '2. Medium Noise':xor_med, \n",
    "                       '3. High Noise':xor_high})\n",
    "target_df = pd.DataFrame({'0.Classifier':names, \n",
    "                       '1. Low Noise':target_low, \n",
    "                       '2. Medium Noise':target_med, \n",
    "                       '3. High Noise':target_high})\n",
    "blob_df = pd.DataFrame({'0.Classifier':names, \n",
    "                       '1. Low Noise':blob_low, \n",
    "                       '2. Medium Noise':blob_med, \n",
    "                       '3. High Noise':blob_high})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.Classifier</th>\n",
       "      <th>1. Low Noise</th>\n",
       "      <th>2. Medium Noise</th>\n",
       "      <th>3. High Noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.931090</td>\n",
       "      <td>0.779247</td>\n",
       "      <td>0.550628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM(Linear)</td>\n",
       "      <td>0.931090</td>\n",
       "      <td>0.784054</td>\n",
       "      <td>0.535273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM(Cubic)</td>\n",
       "      <td>0.870192</td>\n",
       "      <td>0.759215</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-NN</td>\n",
       "      <td>0.935497</td>\n",
       "      <td>0.730369</td>\n",
       "      <td>0.487862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.936298</td>\n",
       "      <td>0.779247</td>\n",
       "      <td>0.535014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.924279</td>\n",
       "      <td>0.762821</td>\n",
       "      <td>0.505187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.934696</td>\n",
       "      <td>0.751603</td>\n",
       "      <td>0.491804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.774840</td>\n",
       "      <td>0.547878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.939904</td>\n",
       "      <td>0.764423</td>\n",
       "      <td>0.531590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.Classifier  1. Low Noise  2. Medium Noise  3. High Noise\n",
       "0          Naive Bayes      0.931090         0.779247       0.550628\n",
       "1          SVM(Linear)      0.931090         0.784054       0.535273\n",
       "2           SVM(Cubic)      0.870192         0.759215       0.500000\n",
       "3                 K-NN      0.935497         0.730369       0.487862\n",
       "4  Logistic Regression      0.936298         0.779247       0.535014\n",
       "5        Decision Tree      0.924279         0.762821       0.505187\n",
       "6        Random Forest      0.934696         0.751603       0.491804\n",
       "7                 MLPC      0.935897         0.774840       0.547878\n",
       "8       Gradient Boost      0.939904         0.764423       0.531590"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "and_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.Classifier</th>\n",
       "      <th>1. Low Noise</th>\n",
       "      <th>2. Medium Noise</th>\n",
       "      <th>3. High Noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.579021</td>\n",
       "      <td>0.514701</td>\n",
       "      <td>0.534803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM(Linear)</td>\n",
       "      <td>0.704634</td>\n",
       "      <td>0.479948</td>\n",
       "      <td>0.530053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM(Cubic)</td>\n",
       "      <td>0.661746</td>\n",
       "      <td>0.733323</td>\n",
       "      <td>0.672917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-NN</td>\n",
       "      <td>0.939045</td>\n",
       "      <td>0.810081</td>\n",
       "      <td>0.595010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.511360</td>\n",
       "      <td>0.485099</td>\n",
       "      <td>0.555506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.939345</td>\n",
       "      <td>0.739474</td>\n",
       "      <td>0.550455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.938745</td>\n",
       "      <td>0.790379</td>\n",
       "      <td>0.571057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.953909</td>\n",
       "      <td>0.800180</td>\n",
       "      <td>0.689569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.954209</td>\n",
       "      <td>0.805031</td>\n",
       "      <td>0.629863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.Classifier  1. Low Noise  2. Medium Noise  3. High Noise\n",
       "0          Naive Bayes      0.579021         0.514701       0.534803\n",
       "1          SVM(Linear)      0.704634         0.479948       0.530053\n",
       "2           SVM(Cubic)      0.661746         0.733323       0.672917\n",
       "3                 K-NN      0.939045         0.810081       0.595010\n",
       "4  Logistic Regression      0.511360         0.485099       0.555506\n",
       "5        Decision Tree      0.939345         0.739474       0.550455\n",
       "6        Random Forest      0.938745         0.790379       0.571057\n",
       "7                 MLPC      0.953909         0.800180       0.689569\n",
       "8       Gradient Boost      0.954209         0.805031       0.629863"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.Classifier</th>\n",
       "      <th>1. Low Noise</th>\n",
       "      <th>2. Medium Noise</th>\n",
       "      <th>3. High Noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.951918</td>\n",
       "      <td>0.709084</td>\n",
       "      <td>0.553285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM(Linear)</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.546819</td>\n",
       "      <td>0.497596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM(Cubic)</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-NN</td>\n",
       "      <td>0.956266</td>\n",
       "      <td>0.739096</td>\n",
       "      <td>0.573718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.643223</td>\n",
       "      <td>0.461184</td>\n",
       "      <td>0.491186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.916624</td>\n",
       "      <td>0.689276</td>\n",
       "      <td>0.522837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.946036</td>\n",
       "      <td>0.733794</td>\n",
       "      <td>0.525641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.927366</td>\n",
       "      <td>0.699680</td>\n",
       "      <td>0.500801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.951918</td>\n",
       "      <td>0.688275</td>\n",
       "      <td>0.536859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.Classifier  1. Low Noise  2. Medium Noise  3. High Noise\n",
       "0          Naive Bayes      0.951918         0.709084       0.553285\n",
       "1          SVM(Linear)      0.643478         0.546819       0.497596\n",
       "2           SVM(Cubic)      0.500000         0.500000       0.500000\n",
       "3                 K-NN      0.956266         0.739096       0.573718\n",
       "4  Logistic Regression      0.643223         0.461184       0.491186\n",
       "5        Decision Tree      0.916624         0.689276       0.522837\n",
       "6        Random Forest      0.946036         0.733794       0.525641\n",
       "7                 MLPC      0.927366         0.699680       0.500801\n",
       "8       Gradient Boost      0.951918         0.688275       0.536859"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.Classifier</th>\n",
       "      <th>1. Low Noise</th>\n",
       "      <th>2. Medium Noise</th>\n",
       "      <th>3. High Noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM(Linear)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM(Cubic)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-NN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998731</td>\n",
       "      <td>0.986679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994924</td>\n",
       "      <td>0.993873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988028</td>\n",
       "      <td>0.960731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998731</td>\n",
       "      <td>0.987905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996193</td>\n",
       "      <td>0.993340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989297</td>\n",
       "      <td>0.987905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.Classifier  1. Low Noise  2. Medium Noise  3. High Noise\n",
       "0          Naive Bayes           1.0         1.000000       0.993340\n",
       "1          SVM(Linear)           1.0         1.000000       0.993340\n",
       "2           SVM(Cubic)           1.0         1.000000       0.986679\n",
       "3                 K-NN           1.0         0.998731       0.986679\n",
       "4  Logistic Regression           1.0         0.994924       0.993873\n",
       "5        Decision Tree           1.0         0.988028       0.960731\n",
       "6        Random Forest           1.0         0.998731       0.987905\n",
       "7                 MLPC           1.0         0.996193       0.993340\n",
       "8       Gradient Boost           1.0         0.989297       0.987905"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Go back through all of the cells above and generate 10 distinct artificial datasets and classify them with all of the available methods. Add a cell immediately below and describe which classifier(s) worked best with which artificially constructed data source and why. Then go through all of the empirical datasets (i.e., Newsgroups, Senate Small, Senate Large, Email Spam) and classify them with all available methods. Add a second cell immediately below and describe which classifier(s) worked best with which data set and why.\n",
    "Stretch (but also required) Wander through the SKLearn documentation available here, particularly perusing the classifiers. In cells following, identify and implement a new classifier that we have not yet used (e.g., AdaBoost, CART) on one artificial dataset and one real dataset (used above). Then, in the next cell describe the classifier, detail how it compares with the approaches above, and why it performed better or worse than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "a = ['Random','And: Low Noise', 'And: Med Noise','And: High Noise', \n",
    "     'Xor: Low Noise', 'Xor: Med Noise','Xor: High Noise', \n",
    "     'Target Split: Low Noise','Target Split: Med Noise','Target Split: High Noise',\n",
    "     'Blobs: Low Noise', 'Blobs: Med Noise','Blobs: High Noise']\n",
    "b = []\n",
    "for i in [1,2,6,10,3,7,11,4,8,12,5,9,13]:\n",
    "    b.append(adaboost[i-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.Dataset</th>\n",
       "      <th>1. AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random</td>\n",
       "      <td>0.492839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And: Low Noise</td>\n",
       "      <td>0.935096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And: Med Noise</td>\n",
       "      <td>0.762821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And: High Noise</td>\n",
       "      <td>0.515302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xor: Low Noise</td>\n",
       "      <td>0.563257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xor: Med Noise</td>\n",
       "      <td>0.519052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Xor: High Noise</td>\n",
       "      <td>0.505301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Target Split: Low Noise</td>\n",
       "      <td>0.951918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Target Split: Med Noise</td>\n",
       "      <td>0.737895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Target Split: High Noise</td>\n",
       "      <td>0.522436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Blobs: Low Noise</td>\n",
       "      <td>0.831395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Blobs: Med Noise</td>\n",
       "      <td>0.865482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Blobs: High Noise</td>\n",
       "      <td>0.862745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.Dataset    1. AUC\n",
       "0                     Random  0.492839\n",
       "1             And: Low Noise  0.935096\n",
       "2             And: Med Noise  0.762821\n",
       "3            And: High Noise  0.515302\n",
       "4             Xor: Low Noise  0.563257\n",
       "5             Xor: Med Noise  0.519052\n",
       "6            Xor: High Noise  0.505301\n",
       "7    Target Split: Low Noise  0.951918\n",
       "8    Target Split: Med Noise  0.737895\n",
       "9   Target Split: High Noise  0.522436\n",
       "10          Blobs: Low Noise  0.831395\n",
       "11          Blobs: Med Noise  0.865482\n",
       "12         Blobs: High Noise  0.862745"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_df = pd.DataFrame({'0.Dataset':a, \n",
    "                       '1. AUC':b})\n",
    "adaboost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.Classifier</th>\n",
       "      <th>1. AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM(Linear)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM(Cubic)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-NN</td>\n",
       "      <td>0.493350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.496419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.484399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.517647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.Classifier    1. AUC\n",
       "0          Naive Bayes  0.500000\n",
       "1          SVM(Linear)  0.500000\n",
       "2           SVM(Cubic)  0.500000\n",
       "3                 K-NN  0.493350\n",
       "4  Logistic Regression  0.500000\n",
       "5        Decision Tree  0.496419\n",
       "6        Random Forest  0.484399\n",
       "7                 MLPC  0.500000\n",
       "8       Gradient Boost  0.517647"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random dataset\n",
    "random = []\n",
    "for i in classifiers:\n",
    "    random.append(i[0])\n",
    "adaboost_df = pd.DataFrame({'0.Classifier':names, \n",
    "                       '1. AUC':random})\n",
    "adaboost_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 275 µs, sys: 946 µs, total: 1.22 ms\n",
      "Wall time: 1.24 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Bayes\n",
    "clf1 = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "#Analogizes\n",
    "clf2 = sklearn.svm.SVC(kernel = 'linear', probability = False) #slow, set probability = False to speed up, but lose ROC\n",
    "clf3 = sklearn.svm.SVC(kernel = 'poly', degree = 3, probability = False) #slower\n",
    "clf4 = sklearn.neighbors.KNeighborsClassifier(5, weights='distance')# k, 'distance' or 'uniform'\n",
    "\n",
    "#Classical Regression\n",
    "clf5 = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "#Symbolists\n",
    "clf6 = sklearn.tree.DecisionTreeClassifier()\n",
    "clf7 = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "#Connectionists\n",
    "clf8 = sklearn.neural_network.MLPClassifier()\n",
    "\n",
    "#Ensemble\n",
    "clf9 = sklearn.ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = [clf1, clf2, clf3, clf4, clf5, clf6, clf7, clf8, clf9]\n",
    "real_train = [train14, train15, train16, train17, train18]\n",
    "real_test = [test14, test15, test16, test17, test18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='distance')\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "CPU times: user 23min 36s, sys: 47.3 s, total: 24min 23s\n",
      "Wall time: 22min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "real_auc = []\n",
    "for i in clfs:\n",
    "    print(str(i))\n",
    "    for j in [0,1,2,3,4]:\n",
    "            x = auc(i,real_train[j],real_test[j])\n",
    "            real_auc.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunk(xs, n):\n",
    "    '''Split the list, xs, into n chunks'''\n",
    "    L = len(xs)\n",
    "    assert 0 < n <= L\n",
    "    s = L//n\n",
    "    return [xs[p:p+s] for p in range(0, L, s)]\n",
    "\n",
    "ds = chunk(real_auc,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds1 = []\n",
    "ds2 = []\n",
    "ds3 = []\n",
    "ds4 = []\n",
    "ds5 = []\n",
    "\n",
    "for i in ds:\n",
    "    ds1.append(i[0])\n",
    "    ds2.append(i[1])\n",
    "    ds3.append(i[2])\n",
    "    ds4.append(i[3])\n",
    "    ds5.append(i[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_df = pd.DataFrame({'0.Classifier':names, \n",
    "                       '1. Reddit': ds1,\n",
    "                       '2. Newsgroups': ds2,\n",
    "                       '3. Senators (Small)': ds3, \n",
    "                       '4. Senators (Large)': ds4,\n",
    "                       '5. Email': ds5})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.Classifier</th>\n",
       "      <th>1. Reddit</th>\n",
       "      <th>2. Newsgroups</th>\n",
       "      <th>3. Senators (Small)</th>\n",
       "      <th>4. Senators (Large)</th>\n",
       "      <th>5. Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.852971</td>\n",
       "      <td>0.896479</td>\n",
       "      <td>0.860712</td>\n",
       "      <td>0.760457</td>\n",
       "      <td>0.813491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM(Linear)</td>\n",
       "      <td>0.991857</td>\n",
       "      <td>0.935699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976070</td>\n",
       "      <td>0.775007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM(Cubic)</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-NN</td>\n",
       "      <td>0.955381</td>\n",
       "      <td>0.586614</td>\n",
       "      <td>0.860694</td>\n",
       "      <td>0.809323</td>\n",
       "      <td>0.711002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.989739</td>\n",
       "      <td>0.944159</td>\n",
       "      <td>0.978873</td>\n",
       "      <td>0.943010</td>\n",
       "      <td>0.629590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.908311</td>\n",
       "      <td>0.875485</td>\n",
       "      <td>0.992958</td>\n",
       "      <td>0.995134</td>\n",
       "      <td>0.768618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.858566</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.976392</td>\n",
       "      <td>0.764505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.997881</td>\n",
       "      <td>0.947074</td>\n",
       "      <td>0.952226</td>\n",
       "      <td>0.954392</td>\n",
       "      <td>0.823810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.977359</td>\n",
       "      <td>0.912663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995495</td>\n",
       "      <td>0.660510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.Classifier  1. Reddit  2. Newsgroups  3. Senators (Small)  \\\n",
       "0          Naive Bayes   0.852971       0.896479             0.860712   \n",
       "1          SVM(Linear)   0.991857       0.935699             1.000000   \n",
       "2           SVM(Cubic)   0.500000       0.500000             0.500000   \n",
       "3                 K-NN   0.955381       0.586614             0.860694   \n",
       "4  Logistic Regression   0.989739       0.944159             0.978873   \n",
       "5        Decision Tree   0.908311       0.875485             0.992958   \n",
       "6        Random Forest   0.914667       0.858566             0.971831   \n",
       "7                 MLPC   0.997881       0.947074             0.952226   \n",
       "8       Gradient Boost   0.977359       0.912663             1.000000   \n",
       "\n",
       "   4. Senators (Large)  5. Email  \n",
       "0             0.760457  0.813491  \n",
       "1             0.976070  0.775007  \n",
       "2             0.500000  0.500000  \n",
       "3             0.809323  0.711002  \n",
       "4             0.943010  0.629590  \n",
       "5             0.995134  0.768618  \n",
       "6             0.976392  0.764505  \n",
       "7             0.954392  0.823810  \n",
       "8             0.995495  0.660510  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
