{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 : Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "/Users/sushmitavgopalan/anaconda/lib/python3.5/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For NLP\n",
    "import nltk\n",
    "\n",
    "import numpy as np #For arrays\n",
    "import pandas as pd #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "\n",
    "#Displays the graphs\n",
    "import graphviz #You also need to install the command line graphviz\n",
    "\n",
    "#These are from the standard library\n",
    "import os.path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import io\n",
    "import tempfile\n",
    "\n",
    "import lucem_illud.stanford as stanford\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "In the cells immediately following, perform POS tagging on a meaningful (but modest) subset of a corpus associated with your final project. Examine the list of words associated with at least three different parts of speech. Consider conditional frequencies (e.g., adjectives associated with nouns of interest or adverbs with verbs of interest). What do these distributions suggest about your corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_csv(\"week7.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>magazine</th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>David Fricke</td>\n",
       "      <td>2017-11-21T16:25:48.392Z</td>\n",
       "      <td>Don Henley Talks 'Hotel California' Reissue, E...</td>\n",
       "      <td>eagles, hotel california, don henley, don henl...</td>\n",
       "      <td>Rolling Stone</td>\n",
       "      <td>\"I was delighted at the energy and grittiness ...</td>\n",
       "      <td>[[``, I, was, delighted, at, the, energy, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Van Sias</td>\n",
       "      <td>2017-10-19T15:17:00.000Z</td>\n",
       "      <td>INXS' 'Kick': 10 Things You Didn't Know</td>\n",
       "      <td>inxs kick, inxs, inxs devil inside, inxs need ...</td>\n",
       "      <td>Rolling Stone</td>\n",
       "      <td>During their first 10 years as a band, INXS we...</td>\n",
       "      <td>[[During, their, first, 10, years, as, a, band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>David Browne</td>\n",
       "      <td>2017-11-08T18:27:46.917Z</td>\n",
       "      <td>Jerry Garcia Band's Ron Tutt Looks Back on 'Ca...</td>\n",
       "      <td>jerry garcia, jerry garcia band, jerry garcia ...</td>\n",
       "      <td>Rolling Stone</td>\n",
       "      <td>Last week, Ron Tutt, best known as Elvis Presl...</td>\n",
       "      <td>[[Last, week, ,, Ron, Tutt, ,, best, known, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Dan Hyman</td>\n",
       "      <td>2018-01-11T20:34:21.946Z</td>\n",
       "      <td>Ralph Steadman: Legendary 'Fear and Loathing' ...</td>\n",
       "      <td>Ralph Steadman, Huncho Jack, Travis Scott, Hun...</td>\n",
       "      <td>Rolling Stone</td>\n",
       "      <td>\"I certainly don't keep up with hip-hop but I'...</td>\n",
       "      <td>[[``, I, certainly, do, n't, keep, up, with, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>David Browne</td>\n",
       "      <td>2017-11-16T19:10:00.000Z</td>\n",
       "      <td>Inside the New Grateful Dead Musical</td>\n",
       "      <td>grateful dead musical, red roses green gold, m...</td>\n",
       "      <td>Rolling Stone</td>\n",
       "      <td>Musical-theater productions tend to gestate fo...</td>\n",
       "      <td>[[Musical-theater, productions, tend, to, gest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Dan Hyman</td>\n",
       "      <td>2017-10-25T17:42:00.000Z</td>\n",
       "      <td>Taylor Bennett on New Artist-Friendly Label, F...</td>\n",
       "      <td>taylor bennett, chance the rapper, chance the ...</td>\n",
       "      <td>Rolling Stone</td>\n",
       "      <td>During the past few years, Taylor's Bennett's ...</td>\n",
       "      <td>[[During, the, past, few, years, ,, Taylor, 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Kory Grow</td>\n",
       "      <td>2018-01-19T19:06:23.752Z</td>\n",
       "      <td>Def Leppard Explain Why They Finally Embraced ...</td>\n",
       "      <td>def leppard,def leppard interview,joe elliott,...</td>\n",
       "      <td>Rolling Stone</td>\n",
       "      <td>For years, Def Leppard were well situated amon...</td>\n",
       "      <td>[[For, years, ,, Def, Leppard, were, well, sit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Elias Leight</td>\n",
       "      <td>2018-01-25T14:31:00.000Z</td>\n",
       "      <td>How the Grammys Finally Got Woke</td>\n",
       "      <td>Grammys, beyonce, Frank Ocean, Kendrick Lamar,</td>\n",
       "      <td>Rolling Stone</td>\n",
       "      <td>On February 12th, 2017, Frank Ocean published ...</td>\n",
       "      <td>[[On, February, 12th, ,, 2017, ,, Frank, Ocean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>David Browne</td>\n",
       "      <td>2017-11-30T16:59:00.000Z</td>\n",
       "      <td>AC/DC's Malcolm Young: Bandmates, Admirers Rem...</td>\n",
       "      <td>malcolm young, malcolm young death, malcolm yo...</td>\n",
       "      <td>Rolling Stone</td>\n",
       "      <td>\"I've never felt like a pop star,\" Malcolm You...</td>\n",
       "      <td>[[``, I, 've, never, felt, like, a, pop, star,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Erik Hedegaard</td>\n",
       "      <td>2018-01-30T16:35:00.000Z</td>\n",
       "      <td>The Sound and the Fury of Meat Loaf: 'I Am Not...</td>\n",
       "      <td>meat loaf</td>\n",
       "      <td>Rolling Stone</td>\n",
       "      <td>As it turns out, in the hill country west of A...</td>\n",
       "      <td>[[As, it, turns, out, ,, in, the, hill, countr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          author                      date  \\\n",
       "0           0    David Fricke  2017-11-21T16:25:48.392Z   \n",
       "1           1        Van Sias  2017-10-19T15:17:00.000Z   \n",
       "2           2    David Browne  2017-11-08T18:27:46.917Z   \n",
       "3           3       Dan Hyman  2018-01-11T20:34:21.946Z   \n",
       "4           4    David Browne  2017-11-16T19:10:00.000Z   \n",
       "5           5       Dan Hyman  2017-10-25T17:42:00.000Z   \n",
       "6           6       Kory Grow  2018-01-19T19:06:23.752Z   \n",
       "7           7    Elias Leight  2018-01-25T14:31:00.000Z   \n",
       "8           8    David Browne  2017-11-30T16:59:00.000Z   \n",
       "9           9  Erik Hedegaard  2018-01-30T16:35:00.000Z   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Don Henley Talks 'Hotel California' Reissue, E...   \n",
       "1            INXS' 'Kick': 10 Things You Didn't Know   \n",
       "2  Jerry Garcia Band's Ron Tutt Looks Back on 'Ca...   \n",
       "3  Ralph Steadman: Legendary 'Fear and Loathing' ...   \n",
       "4               Inside the New Grateful Dead Musical   \n",
       "5  Taylor Bennett on New Artist-Friendly Label, F...   \n",
       "6  Def Leppard Explain Why They Finally Embraced ...   \n",
       "7                   How the Grammys Finally Got Woke   \n",
       "8  AC/DC's Malcolm Young: Bandmates, Admirers Rem...   \n",
       "9  The Sound and the Fury of Meat Loaf: 'I Am Not...   \n",
       "\n",
       "                                            keywords       magazine  \\\n",
       "0  eagles, hotel california, don henley, don henl...  Rolling Stone   \n",
       "1  inxs kick, inxs, inxs devil inside, inxs need ...  Rolling Stone   \n",
       "2  jerry garcia, jerry garcia band, jerry garcia ...  Rolling Stone   \n",
       "3  Ralph Steadman, Huncho Jack, Travis Scott, Hun...  Rolling Stone   \n",
       "4  grateful dead musical, red roses green gold, m...  Rolling Stone   \n",
       "5  taylor bennett, chance the rapper, chance the ...  Rolling Stone   \n",
       "6  def leppard,def leppard interview,joe elliott,...  Rolling Stone   \n",
       "7    Grammys, beyonce, Frank Ocean, Kendrick Lamar,   Rolling Stone   \n",
       "8  malcolm young, malcolm young death, malcolm yo...  Rolling Stone   \n",
       "9                                          meat loaf  Rolling Stone   \n",
       "\n",
       "                                                text  \\\n",
       "0  \"I was delighted at the energy and grittiness ...   \n",
       "1  During their first 10 years as a band, INXS we...   \n",
       "2  Last week, Ron Tutt, best known as Elvis Presl...   \n",
       "3  \"I certainly don't keep up with hip-hop but I'...   \n",
       "4  Musical-theater productions tend to gestate fo...   \n",
       "5  During the past few years, Taylor's Bennett's ...   \n",
       "6  For years, Def Leppard were well situated amon...   \n",
       "7  On February 12th, 2017, Frank Ocean published ...   \n",
       "8  \"I've never felt like a pop star,\" Malcolm You...   \n",
       "9  As it turns out, in the hill country west of A...   \n",
       "\n",
       "                                           sentences  \n",
       "0  [[``, I, was, delighted, at, the, energy, and,...  \n",
       "1  [[During, their, first, 10, years, as, a, band...  \n",
       "2  [[Last, week, ,, Ron, Tutt, ,, best, known, as...  \n",
       "3  [[``, I, certainly, do, n't, keep, up, with, h...  \n",
       "4  [[Musical-theater, productions, tend, to, gest...  \n",
       "5  [[During, the, past, few, years, ,, Taylor, 's...  \n",
       "6  [[For, years, ,, Def, Leppard, were, well, sit...  \n",
       "7  [[On, February, 12th, ,, 2017, ,, Frank, Ocean...  \n",
       "8  [[``, I, 've, never, felt, like, a, pop, star,...  \n",
       "9  [[As, it, turns, out, ,, in, the, hill, countr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores = df\n",
    "redditTopScores['sentences'] = redditTopScores['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "redditTopScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65.1 ms, sys: 194 ms, total: 259 ms\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "redditTopScores['POS_sents'] = redditTopScores['sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[(``, ``), (I, PRP), (was, VBD), (delighted, ...\n",
       "1    [[(During, IN), (their, PRP$), (first, JJ), (1...\n",
       "2    [[(Last, JJ), (week, NN), (,, ,), (Ron, NNP), ...\n",
       "3    [[(``, ``), (I, PRP), (certainly, RB), (do, VB...\n",
       "4    [[(Musical-theater, NN), (productions, NNS), (...\n",
       "5    [[(During, IN), (the, DT), (past, JJ), (few, J...\n",
       "6    [[(For, IN), (years, NNS), (,, ,), (Def, NNP),...\n",
       "7    [[(On, IN), (February, NNP), (12th, JJ), (,, ,...\n",
       "8    [[(``, ``), (I, PRP), ('ve, VBP), (never, RB),...\n",
       "9    [[(As, IN), (it, PRP), (turns, VBZ), (out, RP)...\n",
       "Name: POS_sents, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['POS_sents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('band', 55),\n",
       " ('album', 38),\n",
       " ('\\x89ÛÒ', 35),\n",
       " ('music', 35),\n",
       " ('time', 26),\n",
       " ('year', 23),\n",
       " ('nbsp', 23),\n",
       " (')', 22),\n",
       " ('song', 22),\n",
       " ('show', 21),\n",
       " ('thing', 18),\n",
       " ('rock', 17),\n",
       " ('lot', 17),\n",
       " ('amp', 17),\n",
       " ('way', 17),\n",
       " ('something', 15),\n",
       " ('everything', 14),\n",
       " ('record', 14),\n",
       " (']', 13),\n",
       " ('tour', 12)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'NN'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 48),\n",
       " ('do', 34),\n",
       " ('have', 27),\n",
       " ('go', 20),\n",
       " ('make', 16),\n",
       " ('say', 15),\n",
       " ('get', 15),\n",
       " ('know', 15),\n",
       " ('play', 13),\n",
       " ('sing', 9),\n",
       " ('come', 8),\n",
       " ('see', 8),\n",
       " ('want', 8),\n",
       " ('think', 6),\n",
       " ('take', 6),\n",
       " ('keep', 6),\n",
       " ('give', 6),\n",
       " ('work', 5),\n",
       " ('look', 4),\n",
       " ('try', 4)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'VB'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'own', 'Dead', 'good', 'commercial', 'subscription-based', 'contemporary', 'rough'}\n"
     ]
    }
   ],
   "source": [
    "NTarget = 'JJ'\n",
    "Word = 'music'\n",
    "NResults = set()\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBank = nltk.corpus.treebank\n",
    "treeBank.tagged_sents()[0]\n",
    "treeBank.sents()[0]\n",
    "stanfordTags = stanford.postTagger.tag_sents(treeBank.sents()[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Dutch  \tStanford: JJ\tTreebank: NNP\n",
      "Word: publishing  \tStanford: NN\tTreebank: VBG\n",
      "Word: used  \tStanford: VBD\tTreebank: VBN\n",
      "Word: more  \tStanford: JJR\tTreebank: RBR\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: later  \tStanford: RB\tTreebank: JJ\n",
      "Word: New  \tStanford: NNP\tTreebank: JJ\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: more  \tStanford: JJR\tTreebank: RBR\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: replaced  \tStanford: VBD\tTreebank: VBN\n",
      "Word: more  \tStanford: JJR\tTreebank: JJ\n",
      "Word: expected  \tStanford: VBD\tTreebank: VBN\n",
      "Word: study  \tStanford: VBD\tTreebank: VBP\n",
      "Word: studied  \tStanford: VBD\tTreebank: VBN\n",
      "Word: industrialized  \tStanford: JJ\tTreebank: VBN\n",
      "Word: Lorillard  \tStanford: NNP\tTreebank: NN\n",
      "Word: found  \tStanford: VBD\tTreebank: VBN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: rejected  \tStanford: VBD\tTreebank: VBN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: poured  \tStanford: VBN\tTreebank: VBD\n",
      "Word: in  \tStanford: IN\tTreebank: RP\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "The Precision is 96.547%\n"
     ]
    }
   ],
   "source": [
    "NumDiffs = 0\n",
    "for sentIndex in range(len(stanfordTags)):\n",
    "    for wordIndex in range(len(stanfordTags[sentIndex])):\n",
    "        if stanfordTags[sentIndex][wordIndex][1] != treeBank.tagged_sents()[sentIndex][wordIndex][1]:\n",
    "            if treeBank.tagged_sents()[sentIndex][wordIndex][1] != '-NONE-':\n",
    "                print(\"Word: {}  \\tStanford: {}\\tTreebank: {}\".format(stanfordTags[sentIndex][wordIndex][0], stanfordTags[sentIndex][wordIndex][1], treeBank.tagged_sents()[sentIndex][wordIndex][1]))\n",
    "                NumDiffs += 1\n",
    "total = sum([len(s) for s in stanfordTags])\n",
    "print(\"The Precision is {:.3f}%\".format((total-NumDiffs)/total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
